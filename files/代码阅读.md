

# 涉及到的工具定义

```C++
void readParameters(const string &config_file);  // 读取配置文件
enum SIZE_PARAMETERIZATION{}  // 参数个数
enum StateOrder{}  // 状态顺序
enum NoiseOrder{}  // 噪声顺序
class TicToc{}  //
class Utility{}
class FeaturePerFrame{}  // 每帧特征
class FeaturePerId{}  // 每个ID特征
class FeatureManager{}  // 特征管理器
class InitialBiasFactor : public ceres::SizedCostFunction<6, 9>{}  // 初始偏移因子
class InitialPoseFactor : public ceres::SizedCostFunction<6, 7>{}  // 初始位姿因子
class IntegrationBase{}  // 积分基础
class IMUFactor : public ceres::SizedCostFunction<15, 7, 9, 7, 9>{}  // IMU因子
struct ResidualBlockInfo{}  // 残差块信息
struct ThreadsStruct{}  // 线程结构
class MarginalizationInfo{}  // 边缘化信息
class MarginalizationFactor : public ceres::CostFunction{}  // 边缘化因子
class PoseLocalParameterization : public ceres::LocalParameterization{}  // 局部位姿参数化
class ProjectionFactor : public ceres::SizedCostFunction<2, 7, 7, 7, 1>{}  // 投影因子
class ProjectionOneFrameTwoCamFactor : public ceres::SizedCostFunction<2, 7, 7, 1, 1>{}  // 单帧两相机投影因子
class ProjectionTwoFrameOneCamFactor : public ceres::SizedCostFunction<2, 7, 7, 7, 1, 1>{}  // 双帧单相机投影因子
class ProjectionTwoFrameTwoCamFactor : public ceres::SizedCostFunction<2, 7, 7, 7, 7, 1, 1>{}  // 双帧双因子投影因子
class ImageFrame{}  // 图像帧
void solveGyroscopeBias(map<double, ImageFrame> &all_image_frame, Vector3d* Bgs);  // 求解陀螺仪误差
bool VisualIMUAlignment(map<double, ImageFrame> &all_image_frame, Vector3d* Bgs, Vector3d &g, VectorXd &x);  // 视觉IMU分布
class InitialEXRotation{}  // 初始化EX旋转
struct SFMFeature{}  // SFM特征
struct ReprojectionError3D{}  // 三维重投影误差
class GlobalSFM{}  // 全局SFM
class MotionEstimator{}  // 运动估计器
bool inBorder(const cv::Point2f &pt);  // 
void reduceVector(vector<cv::Point2f> &v, vector<uchar> status);  // 
void reduceVector(vector<int> &v, vector<uchar> status);  //
class FeatureTracker{}  // 特征跟踪器
class Estimator{}  // 估计器
void printStatistics(const Estimator &estimator, double t);  // 打印统计数据
void pubOdometry(const Estimator &estimator, const std_msgs::Header &header);  // 发布里程计信息
```



# estimator类定义

```C++
class Estimator
{
  public:
    Estimator();  // 构造
    ~Estimator();  // 析构
    void setParameter();  // 设参数

    // interface  交互
    void initFirstPose(Eigen::Vector3d p, Eigen::Matrix3d r);  // 初始最先位姿
    void inputIMU(double t, const Vector3d &linearAcceleration, const Vector3d &angularVelocity);  // 输入IMU
    void inputFeature(double t, const map<int, vector<pair<int, Eigen::Matrix<double, 7, 1>>>> &featureFrame);  // 输入特征
    void inputImage(double t, const cv::Mat &_img, const cv::Mat &_img1 = cv::Mat());  // 输入图像
    void processIMU(double t, double dt, const Vector3d &linear_acceleration, const Vector3d &angular_velocity);  // 处理IMU
    void processImage(const map<int, vector<pair<int, Eigen::Matrix<double, 7, 1>>>> &image, const double header);  // 处理图像
    void processMeasurements();  // 处理测量值
    void changeSensorType(int use_imu, int use_stereo);  // 改变传感器类型

    // internal  内核
    void clearState();  // 清除状态
    bool initialStructure();  // 初始化结构
    bool visualInitialAlign();  // 视觉初始分布
    bool relativePose(Matrix3d &relative_R, Vector3d &relative_T, int &l);  // 相对位姿计算
    void slideWindow();  // 滑动窗口
    void slideWindowNew();  // 新滑动窗口
    void slideWindowOld();  // 旧滑动窗口
    void optimization();   // 优化
    void vector2double();  // vector转double
    void double2vector();  // double转vector
    bool failureDetection();  // 失败检测
    bool getIMUInterval(double t0, double t1, vector<pair<double, Eigen::Vector3d>> &accVector, 
                                              vector<pair<double, Eigen::Vector3d>> &gyrVector);  // 获取IMU间隙
    void getPoseInWorldFrame(Eigen::Matrix4d &T);  // 在世界坐标系中获取位姿
    void getPoseInWorldFrame(int index, Eigen::Matrix4d &T);
    void predictPtsInNextFrame();  // 预测下一帧像素/得分？
    void outliersRejection(set<int> &removeIndex);  // 外点剔除
    double reprojectionError(Matrix3d &Ri, Vector3d &Pi, Matrix3d &rici, Vector3d &tici,
                                     Matrix3d &Rj, Vector3d &Pj, Matrix3d &ricj, Vector3d &ticj, 
                                     double depth, Vector3d &uvi, Vector3d &uvj);  // 重投影误差
    void updateLatestStates();  // 更新最新状态
    void fastPredictIMU(double t, Eigen::Vector3d linear_acceleration, Eigen::Vector3d angular_velocity);  // 快速预测IMU
    bool IMUAvailable(double t);  // IMU可获取？
    void initFirstIMUPose(vector<pair<double, Eigen::Vector3d>> &accVector);  // 初始最先IMU位姿

    enum SolverFlag  // 求解器flag
    {
        INITIAL,
        NON_LINEAR
    };

    enum MarginalizationFlag  // 边缘化flag
    {
        MARGIN_OLD = 0,
        MARGIN_SECOND_NEW = 1
    };
	// mutex为一个互斥锁对象，用于在代码的关键部分需要独占访问时发出信号，防止具有相同保护的其他线程同时执行和访问相同的内存位置。（https://www.cplusplus.com/reference/mutex/mutex/）
    std::mutex mProcess;  // 处理锁
    std::mutex mBuf;   // 缓存锁
    // queue（队列）为一种容器适配器，专门设计用于在FIFO内容中运行（先进先出），其中元素插入容器的一端并从另一端提取。
    // pair，把一对值组合在一起，可能是不同的类型（T1和T2），并且可以通过公共成员first和second获取独立的变量。
    // map，按照特定顺序存储的由键值和映射值组合形成的元素的关联容器
    queue<pair<double, Eigen::Vector3d>> accBuf;
    queue<pair<double, Eigen::Vector3d>> gyrBuf;
    queue<pair<double, map<int, vector<pair<int, Eigen::Matrix<double, 7, 1> > > > > > featureBuf;  // 特征点缓存，一个整形与一个vector对应
    double prevTime, curTime;  // 先前时间，当前时间
    bool openExEstimation;  // 打开估计器
	
    // thread，表示运行程序的单独线程
    std::thread trackThread;  // 跟踪线程
    std::thread processThread;  // 处理线程

    FeatureTracker featureTracker;

    SolverFlag solver_flag;
    MarginalizationFlag  marginalization_flag;
    Vector3d g;

    Matrix3d ric[2];
    Vector3d tic[2];

    Vector3d        Ps[(WINDOW_SIZE + 1)];
    Vector3d        Vs[(WINDOW_SIZE + 1)];
    Matrix3d        Rs[(WINDOW_SIZE + 1)];
    Vector3d        Bas[(WINDOW_SIZE + 1)];
    Vector3d        Bgs[(WINDOW_SIZE + 1)];
    double td;

    Matrix3d back_R0, last_R, last_R0;
    Vector3d back_P0, last_P, last_P0;
    double Headers[(WINDOW_SIZE + 1)];

    IntegrationBase *pre_integrations[(WINDOW_SIZE + 1)];
    Vector3d acc_0, gyr_0;

    vector<double> dt_buf[(WINDOW_SIZE + 1)];
    vector<Vector3d> linear_acceleration_buf[(WINDOW_SIZE + 1)];
    vector<Vector3d> angular_velocity_buf[(WINDOW_SIZE + 1)];

    int frame_count;
    int sum_of_outlier, sum_of_back, sum_of_front, sum_of_invalid;
    int inputImageCnt;

    FeatureManager f_manager;
    MotionEstimator m_estimator;
    InitialEXRotation initial_ex_rotation;

    bool first_imu;
    bool is_valid, is_key;
    bool failure_occur;

    vector<Vector3d> point_cloud;
    vector<Vector3d> margin_cloud;
    vector<Vector3d> key_poses;
    double initial_timestamp;


    double para_Pose[WINDOW_SIZE + 1][SIZE_POSE];
    double para_SpeedBias[WINDOW_SIZE + 1][SIZE_SPEEDBIAS];
    double para_Feature[NUM_OF_F][SIZE_FEATURE];
    double para_Ex_Pose[2][SIZE_POSE];
    double para_Retrive_Pose[SIZE_POSE];
    double para_Td[1][1];
    double para_Tr[1][1];

    int loop_window_index;

    MarginalizationInfo *last_marginalization_info;
    vector<double *> last_marginalization_parameter_blocks;

    map<double, ImageFrame> all_image_frame;
    IntegrationBase *tmp_pre_integration;

    Eigen::Vector3d initP;
    Eigen::Matrix3d initR;

    double latest_time;
    Eigen::Vector3d latest_P, latest_V, latest_Ba, latest_Bg, latest_acc_0, latest_gyr_0;
    Eigen::Quaterniond latest_Q;

    bool initFirstPoseFlag;
    bool initThreadFlag;
};
```



# vins_estimator main.cpp详读

```C++
#include "tools.h"


#define _USE_MATH_DEFINES
#define SHOW_UNDISTORTION 0

// static FeatureTracker trackerData[NUM_OF_CAM];
static Estimator estimator;

queue<sensor_msgs::ImuConstPtr> imu_buf;
queue<sensor_msgs::PointCloudConstPtr> feature_buf;
queue<pair<cv::Mat, double>> img0_buf;
queue<pair<cv::Mat, double>> img1_buf;

std::mutex m_buf;

// void img0_callback(const sensor_msgs::ImageConstPtr &img_msg)
void img0_callback(const cv::Mat &img_msg, const double &t)
{
    m_buf.lock();
    pair<cv::Mat, double> tmp;
    tmp.first=img_msg;
    tmp.second=t;
    img0_buf.push(tmp);
    m_buf.unlock();
}

void img1_callback(const cv::Mat &img_msg, const double &t)
{
    m_buf.lock();
    pair<cv::Mat, double> tmp;
    tmp.first=img_msg;
    tmp.second=t;
    img1_buf.push(tmp);
    m_buf.unlock();
}

// extract images with same timestamp from two topics
void sync_process()
{
    while(1)
    {
        if(STEREO)
        {
            cv::Mat image0, image1;
            std_msgs::Header header;
            double time = 0;
            m_buf.lock();
            if (!img0_buf.empty() && !img1_buf.empty())
            {
                double time0 = img0_buf.front().second;
                double time1 = img1_buf.front().second;
                // 0.003s sync tolerance
                if(time0 < time1 - 0.003)
                {
                    img0_buf.pop();
                    printf("throw img0\n");
                }
                else if(time0 > time1 + 0.003)
                {
                    img1_buf.pop();
                    printf("throw img1\n");
                }
                else
                {
                    time = img0_buf.front().second;
                    image0 = img0_buf.front().first;
                    img0_buf.pop();
                    image1 = img1_buf.front().first;
                    img1_buf.pop();
                }
            }
            m_buf.unlock();
            if(!image0.empty())
                estimator.inputImage(time, image0, image1);
        }
        else
        {
            cv::Mat image;
            std_msgs::Header header;
            double time = 0;
            m_buf.lock();
            if(!img0_buf.empty())
            {
                time = img0_buf.front().second;
                image = img0_buf.front().first;
                img0_buf.pop();
            }
            m_buf.unlock();
            if(!image.empty())
                estimator.inputImage(time, image);
        }

        std::chrono::milliseconds dura(1);
        std::this_thread::sleep_for(dura);
    }
}


void imu_callback(const sensor_msgs::ImuConstPtr &imu_msg)
{
    double t = imu_msg->header.stamp.toSec();
    double dx = imu_msg->linear_acceleration.x;
    double dy = imu_msg->linear_acceleration.y;
    double dz = imu_msg->linear_acceleration.z;
    double rx = imu_msg->angular_velocity.x;
    double ry = imu_msg->angular_velocity.y;
    double rz = imu_msg->angular_velocity.z;
    Vector3d acc(dx, dy, dz);
    Vector3d gyr(rx, ry, rz);
    estimator.inputIMU(t, acc, gyr);
    return;
}

void LoadImages(const string &strImagePath, const string &strTimesStampsPath,
        vector<string> &strImagesFileNames, vector<double> &timeStamps)
{
    ifstream fTimes;
    fTimes.open(strTimesStampsPath.c_str());
    timeStamps.reserve(5000); //reserve vector space
    strImagesFileNames.reserve(5000); 
    while(!fTimes.eof())
    {
        string s;
        getline(fTimes,s);
        if(!s.empty())
        {
            stringstream ss;
            ss << s;
            strImagesFileNames.push_back(strImagePath + "/" + ss.str() + ".png");
            double t;
            ss >> t;
            timeStamps.push_back(t/1e9);
        }
    }
}
/******************* load image end ***********************/

/******************* load IMU begin ***********************/

void LoadImus(ifstream & fImus, const ros::Time &imageTimestamp)
{

    while(!fImus.eof())
    {
        string s;
        getline(fImus,s);
        if(!s.empty())
        {
            char c = s.at(0);
            if(c<'0' || c>'9')      //remove first line in data.csv
                continue;
            stringstream ss;
            ss << s;
            double tmpd;
            int cnt=0;
            double data[7];
            while(ss >> tmpd)
            {
            data[cnt] = tmpd;
            cnt++;
            if(cnt ==7)
              break;
            if(ss.peek() == ',' || ss.peek() == ' ')
              ss.ignore();
            }
            data[0] *=1e-9; //convert to second unit
            sensor_msgs::ImuPtr imudata(new sensor_msgs::Imu);
            imudata->angular_velocity.x = data[1];
            imudata->angular_velocity.y = data[2];
            imudata->angular_velocity.z = data[3];
            imudata->linear_acceleration.x = data[4];
            imudata->linear_acceleration.y = data[5];
            imudata->linear_acceleration.z = data[6];
            uint32_t  sec = data[0];
            uint32_t nsec = (data[0]-sec)*1e9;
            nsec = (nsec/1000)*1000+500;
            imudata->header.stamp = ros::Time(sec,nsec);
            imu_callback(imudata);
            if (imudata->header.stamp > imageTimestamp)       //load all imu data produced in interval time between two consecutive frams
                break;
        }
    }
}

int main(int argc, char **argv)
{
  /******************* load image begin ***********************/
    // 首先检测指令后的字符串数量
    if(argc != 5 && argc!=7)
    {
        cout << argc << endl;
        cerr << endl << "Usage: ./vins_estimator path_to_setting_file path_to_image_folder path_to_times_file path_to_imu_data_file" <<endl;
        return 1;
    }
    
    // 读取参数部分
    readParameters(argv[1]);  // 读取配置文件
    estimator.setParameter();  // 估计器设置参数

    if (!STEREO)  // 判断是否为双目
    {
        /******************************* 对于单目相机 **********************************/
        //imu data file 
        ifstream fImus;
        fImus.open(argv[4]);

        cv::Mat image;
        int ni;//num image
    
        vector<string> vStrImagesFileNames;
        vector<double> vTimeStamps;
        LoadImages(string(argv[2]),string(argv[3]),vStrImagesFileNames,vTimeStamps);
        
        int imageNum = vStrImagesFileNames.size();
        
        if(imageNum<=0)
        {
        cerr << "ERROR: Failed to load images" << endl;
        return 1;
        }
        
        std::thread measurement_process{sync_process};
        
         measurement_process.detach();
       
        for(ni=0; ni<imageNum; ni++)
        {

          double  tframe = vTimeStamps[ni];   //timestamp
          uint32_t  sec = tframe;
          uint32_t nsec = (tframe-sec)*1e9;
          nsec = (nsec/1000)*1000+500;
          ros::Time image_timestamp = ros::Time(sec, nsec);
           // read imu data
          LoadImus(fImus,image_timestamp);
           
        //read image from file
          image = cv::imread(vStrImagesFileNames[ni],cv::IMREAD_UNCHANGED);
          
          if(image.empty())
          {
          cerr << endl << "Failed to load image: " << vStrImagesFileNames[ni] <<endl;
          return 1;
          }
          std::chrono::steady_clock::time_point t1 = std::chrono::steady_clock::now();
          img0_callback(image, image_timestamp.toSec());
          std::chrono::steady_clock::time_point t2 = std::chrono::steady_clock::now();
          double timeSpent =std::chrono::duration_cast<std::chrono::duration<double>>(t2-t1).count();
          
          //wait to load the next frame image
          double T=0;
          if(ni < imageNum-1)
        T = vTimeStamps[ni+1]-tframe; //interval time between two consecutive frames,unit:second
          else if(ni>0)    //lastest frame
        T = tframe-vTimeStamps[ni-1];
          
          if(timeSpent < T)
        usleep((T-timeSpent)*1e6); //sec->us:1e6
          else
        cerr << endl << "process image speed too slow, larger than interval time between two consecutive frames" << endl;
          
        }
    }
    else if(STEREO)
    {
        /******************************* 对于双目相机 **********************************/
        //imu data file 
        ifstream fImus;  // 数据流
        fImus.open(argv[6]); // 读取IMU数据，包含

        cv::Mat image;
        cv::Mat image2;
        int ni;  //num image

        vector<string> vStrImagesFileNames;
        vector<string> vStrImagesFileNames2 ;
        vector<double> vTimeStamps;
        vector<double> vTimeStamps2;
        LoadImages(string(argv[2]),string(argv[4]),vStrImagesFileNames,vTimeStamps); //left
        LoadImages(string(argv[3]),string(argv[5]),vStrImagesFileNames2,vTimeStamps2); //right
        
        int tmp_imageNum = vStrImagesFileNames.size();
        int tmp_imageNum2 = vStrImagesFileNames2.size();
        int imageNum = (tmp_imageNum<tmp_imageNum2)?tmp_imageNum2:tmp_imageNum; // I am good at coding. hahaha

        
        if(imageNum<=0)
        {
            cerr << "ERROR: Failed to load images" << endl;
            return 1;
        }
        
        std::thread measurement_process{sync_process};
        
        measurement_process.detach();
       
        for(ni=0; ni<imageNum; ni++)
        {
            double  tframe = vTimeStamps[ni];   //timestamp
            uint32_t  sec = tframe;
            uint32_t nsec = (tframe-sec)*1e9;
            nsec = (nsec/1000)*1000+500;
            ros::Time image_timestamp = ros::Time(sec, nsec);
            double  tframe2 = vTimeStamps2[ni];   //timestamp
            uint32_t  sec2 = tframe2;
            uint32_t nsec2 = (tframe2-sec2)*1e9;
            nsec2 = (nsec2/1000)*1000+500;
            ros::Time image_timestamp2 = ros::Time(sec2, nsec2);
            // read imu data
            LoadImus(fImus,image_timestamp); //TODO

            //read image from file
            image = cv::imread(vStrImagesFileNames[ni],cv::IMREAD_UNCHANGED);
            image2 = cv::imread(vStrImagesFileNames2[ni],cv::IMREAD_UNCHANGED);

            if(image.empty() or image2.empty())
            {
              cerr << endl << "Failed to load image: " << vStrImagesFileNames[ni] <<endl;
              return 1;
            }
            std::chrono::steady_clock::time_point t1 = std::chrono::steady_clock::now();
            img0_callback(image, image_timestamp.toSec());
            img1_callback(image2, image_timestamp2.toSec());
            std::chrono::steady_clock::time_point t2 = std::chrono::steady_clock::now();
            double timeSpent =std::chrono::duration_cast<std::chrono::duration<double>>(t2-t1).count();

            //wait to load the next frame image
            double T=0;
            if(ni < imageNum-1)
            T = vTimeStamps[ni+1]-tframe; //interval time between two consecutive frames,unit:second
            else if(ni>0)    //lastest frame
            T = tframe-vTimeStamps[ni-1];

            if(timeSpent < T)
            usleep((T-timeSpent)*1e6); //sec->us:1e6
            else
            cerr << endl << "process image speed too slow, larger than interval time between two consecutive frames" << endl;
        }

        return 0;
    }
}

```



# FeatureTracker

```c++
class FeatureTracker
{
public:
    FeatureTracker();
    map<int, vector<pair<int, Eigen::Matrix<double, 7, 1>>>> trackImage(double _cur_time, const cv::Mat &_img, const cv::Mat &_img1 = cv::Mat());
    void setMask();
    void addPoints();
    void readIntrinsicParameter(const vector<string> &calib_file);
    // void readIntrinsicParameter(const string &calib_file);
    void showUndistortion(const string &name);
    void rejectWithF();
    void undistortedPoints();
    vector<cv::Point2f> undistortedPts(vector<cv::Point2f> &pts, camodocal::CameraPtr cam);
    vector<cv::Point2f> ptsVelocity(vector<int> &ids, vector<cv::Point2f> &pts, 
                                    map<int, cv::Point2f> &cur_id_pts, map<int, cv::Point2f> &prev_id_pts);
    void showTwoImage(const cv::Mat &img1, const cv::Mat &img2, 
                      vector<cv::Point2f> pts1, vector<cv::Point2f> pts2);
    void drawTrack(const cv::Mat &imLeft, const cv::Mat &imRight, 
                                   vector<int> &curLeftIds,
                                   vector<cv::Point2f> &curLeftPts, 
                                   vector<cv::Point2f> &curRightPts,
                                   map<int, cv::Point2f> &prevLeftPtsMap);
    void setPrediction(map<int, Eigen::Vector3d> &predictPts);
    double distance(cv::Point2f &pt1, cv::Point2f &pt2);
    void removeOutliers(set<int> &removePtsIds);
    cv::Mat getTrackImage();
    bool inBorder(const cv::Point2f &pt);

    int row, col;
    cv::Mat imTrack;
    cv::Mat mask;
    cv::Mat prev_img, cur_img;
    vector<cv::Point2f> n_pts;
    int sum_n;
    vector<cv::Point2f> predict_pts;
    vector<cv::Point2f> predict_pts_debug;
    vector<cv::Point2f> prev_pts, cur_pts, cur_right_pts;
    vector<cv::Point2f> prev_un_pts, cur_un_pts, cur_un_right_pts;
    vector<cv::Point2f> pts_velocity, right_pts_velocity;
    vector<int> ids, ids_right;
    vector<int> track_cnt;
    map<int, cv::Point2f> cur_un_pts_map, prev_un_pts_map;
    map<int, cv::Point2f> cur_un_right_pts_map, prev_un_right_pts_map;
    map<int, cv::Point2f> prevLeftPtsMap;
    vector<camodocal::CameraPtr> m_camera;
    double cur_time;
    double prev_time;
    bool stereo_cam;
    int n_id;
    bool hasPrediction;
};
```

